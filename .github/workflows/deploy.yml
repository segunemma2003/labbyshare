name: Deploy to Production

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: labmyshare2020
          POSTGRES_DB: labmyshare_db
          POSTGRES_USER: labmyshare
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-django pytest-cov

      - name: Set up test environment
        run: |
          cp .env.example .env
          echo "DEBUG=True" >> .env
          echo "SECRET_KEY=test-secret-key-for-github-actions" >> .env
          echo "DB_NAME=labmyshare_db" >> .env
          echo "DB_USER=labmyshare" >> .env
          echo "DB_PASSWORD=labmyshare2020" >> .env
          echo "DB_HOST=localhost" >> .env
          echo "DB_PORT=5432" >> .env
          echo "REDIS_URL=redis://localhost:6379/1" >> .env
          echo "CELERY_BROKER_URL=redis://localhost:6379/0" >> .env
          echo "CELERY_RESULT_BACKEND=redis://localhost:6379/0" >> .env

      - name: Run migrations
        run: |
          python manage.py migrate --run-syncdb

      - name: Run tests
        run: |
          python manage.py test

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    permissions:
      contents: read
      packages: write

    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

  deploy:
    needs: [test, build]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    environment:
      name: production
      url: http://backend.beautyspabyshea.co.uk:8080

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.7.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts

      - name: Create deployment files
        run: |
          # Create docker-compose.yml
          cat > docker-compose.fixed.yml << 'EOF'
          services:
            db:
              container_name: labmyshare_db
              image: postgres:15
              restart: unless-stopped
              environment:
                POSTGRES_DB: labmyshare_db
                POSTGRES_USER: labmyshare
                POSTGRES_PASSWORD: labmyshare2020
              volumes:
                - postgres_data:/var/lib/postgresql/data/
                - ./backups/postgres:/backups
              ports:
                - "127.0.0.1:5432:5432"
              healthcheck:
                test: ["CMD-SHELL", "pg_isready -U labmyshare -d labmyshare_db"]
                interval: 10s
                timeout: 5s
                retries: 5
                start_period: 30s
              networks:
                - labmyshare_network

            redis:
              container_name: labmyshare_redis
              image: redis:7-alpine
              restart: unless-stopped
              command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
              volumes:
                - redis_data:/data
              ports:
                - "127.0.0.1:6379:6379"
              healthcheck:
                test: ["CMD", "redis-cli", "ping"]
                interval: 10s
                timeout: 5s
                retries: 5
              networks:
                - labmyshare_network

            web:
              container_name: labmyshare_web
              image: ghcr.io/${{ github.repository }}:latest
              restart: unless-stopped
              command: >
                sh -c "
                  echo 'Waiting for database...' &&
                  until nc -z db 5432; do sleep 2; done &&
                  echo 'Database ready!' &&
                  python manage.py migrate --noinput &&
                  python manage.py collectstatic --noinput &&
                  gunicorn labmyshare.wsgi:application --bind 0.0.0.0:8000 --workers 4 --threads 2 --timeout 120
                "
              volumes:
                - static_volume:/app/staticfiles
                - media_volume:/app/media
                - logs_volume:/app/logs
              ports:
                - "127.0.0.1:8000:8000"
              env_file:
                - .env
              depends_on:
                db:
                  condition: service_healthy
                redis:
                  condition: service_healthy
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 90s
              networks:
                - labmyshare_network

            celery:
              container_name: labmyshare_celery
              image: ghcr.io/${{ github.repository }}:latest
              restart: unless-stopped
              command: >
                sh -c "
                  until nc -z db 5432 && nc -z redis 6379; do sleep 2; done &&
                  celery -A labmyshare worker --loglevel=info --concurrency=4
                "
              volumes:
                - media_volume:/app/media
                - logs_volume:/app/logs
              env_file:
                - .env
              depends_on:
                - db
                - redis
              healthcheck:
                test: ["CMD", "celery", "-A", "labmyshare", "inspect", "ping"]
                interval: 30s
                timeout: 10s
                retries: 3
              networks:
                - labmyshare_network

            celery-beat:
              container_name: labmyshare_celery_beat
              image: ghcr.io/${{ github.repository }}:latest
              restart: unless-stopped
              command: >
                sh -c "
                  until nc -z db 5432 && nc -z redis 6379; do sleep 2; done &&
                  celery -A labmyshare beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
                "
              volumes:
                - logs_volume:/app/logs
              env_file:
                - .env
              depends_on:
                - db
                - redis
              healthcheck:
                test: ["CMD", "pgrep", "-f", "celery.*beat"]
                interval: 30s
                timeout: 10s
                retries: 3
              networks:
                - labmyshare_network

            nginx:
              container_name: labmyshare_nginx
              image: nginx:alpine
              restart: unless-stopped
              ports:
                - "8080:80"
              volumes:
                - ./docker/nginx/http-only.conf:/etc/nginx/conf.d/default.conf:ro
                - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
                - static_volume:/var/www/static:ro
                - media_volume:/var/www/media:ro
                - nginx_logs:/var/log/nginx
              depends_on:
                web:
                  condition: service_healthy
              networks:
                - labmyshare_network

            db-backup:
              container_name: labmyshare_db_backup
              image: postgres:15
              restart: unless-stopped
              environment:
                POSTGRES_DB: labmyshare_db
                POSTGRES_USER: labmyshare
                POSTGRES_PASSWORD: labmyshare2020
                PGPASSWORD: labmyshare2020
              volumes:
                - ./backups/postgres:/backups
              command: >
                sh -c "
                  until nc -z db 5432; do sleep 5; done &&
                  echo '0 2 * * * cd /backups && pg_dump -h db -U labmyshare -d labmyshare_db > backup_$$(date +%%Y%%m%%d_%%H%%M%%S).sql' | crontab - &&
                  crond -f
                "
              depends_on:
                db:
                  condition: service_healthy
              networks:
                - labmyshare_network

          volumes:
            postgres_data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/postgres
            redis_data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/redis
            static_volume:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/static
            media_volume:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/media
            logs_volume:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/logs
            nginx_logs:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/nginx-logs

          networks:
            labmyshare_network:
              driver: bridge
          EOF

          # Create nginx config
          cat > nginx.conf << 'EOF'
          user nginx;
          worker_processes auto;
          error_log /var/log/nginx/error.log warn;
          pid /var/run/nginx.pid;
          events {
            worker_connections 1024;
          }
          http {
            include /etc/nginx/mime.types;
            default_type application/octet-stream;
            sendfile on;
            keepalive_timeout 65;
            include /etc/nginx/conf.d/*.conf;
          }
          EOF

          # Create nginx site config
          cat > http-only.conf << 'EOF'
          upstream labmyshare {
            server web:8000 max_fails=3 fail_timeout=30s;
          }
          
          server {
            listen 80;
            server_name backend.beautyspabyshea.co.uk localhost;
            
            # Increase timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # Main application
            location / {
              proxy_pass http://labmyshare;
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $scheme;
              proxy_set_header Connection "";
              proxy_http_version 1.1;
              
              # Add error handling
              proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            }
            
            # Health check endpoint
            location /health/ {
              proxy_pass http://labmyshare;
              proxy_set_header Host $host;
              access_log off;
              
              # Shorter timeouts for health checks
              proxy_connect_timeout 10s;
              proxy_send_timeout 10s;
              proxy_read_timeout 10s;
            }
            
            # Alternative health check without trailing slash
            location /health {
              proxy_pass http://labmyshare;
              proxy_set_header Host $host;
              access_log off;
              
              proxy_connect_timeout 10s;
              proxy_send_timeout 10s;
              proxy_read_timeout 10s;
            }
            
            # Static files
            location /static/ {
              alias /var/www/static/;
              expires 30d;
              add_header Cache-Control "public, immutable";
            }
            
            # Media files
            location /media/ {
              alias /var/www/media/;
              expires 7d;
              add_header Cache-Control "public";
            }
            
            # Nginx status endpoint for debugging
            location /nginx-status {
              stub_status on;
              access_log off;
              allow 127.0.0.1;
              allow 172.0.0.0/8;
              deny all;
            }
          }
          EOF

          # Create management command
          cat > create_initial_data.py << 'EOF'
          from django.core.management.base import BaseCommand
          from django.contrib.auth import get_user_model
          
          User = get_user_model()
          
          class Command(BaseCommand):
              help = "Create initial data"
              
              def handle(self, *args, **options):
                  try:
                      admin_email = "admin@labmyshare.com"
                      if not User.objects.filter(email=admin_email).exists():
                          User.objects.create_superuser(
                              username="admin",
                              email=admin_email,
                              password="admin123"
                          )
                          print("✅ Superuser created")
                      else:
                          print("ℹ️  Superuser already exists")
                  except Exception as e:
                      print(f"❌ Error: {e}")
          EOF

          # Create .env file
          cat > production.env << 'EOF'
          SECRET_KEY=ghfjgk.hl;iogulfkydjtxfgcvjbk.hllfkdtjxgchvjgkifuydcghvjgv
          DEBUG=False
          ALLOWED_HOSTS=backend.beautyspabyshea.co.uk,localhost,127.0.0.1
          DB_NAME=labmyshare_db
          DB_USER=labmyshare
          DB_PASSWORD=labmyshare2020
          DB_HOST=db
          DB_PORT=5432
          REDIS_URL=redis://redis:6379/1
          CELERY_BROKER_URL=redis://redis:6379/0
          CELERY_RESULT_BACKEND=redis://redis:6379/0
          EMAIL_HOST=smtp.resend.com
          EMAIL_PORT=587
          EMAIL_HOST_USER=resend
          EMAIL_HOST_PASSWORD=re_ZBwZZ2tj_AMtGvcpxoa1DofEXdV3BKM2f
          DEFAULT_FROM_EMAIL=noreply@beautyspabyshea.co.uk
          GITHUB_REPOSITORY=${{ github.repository }}
          EOF

      - name: Copy files to server
        run: |
          scp docker-compose.fixed.yml ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }}:/tmp/
          scp nginx.conf ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }}:/tmp/
          scp http-only.conf ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }}:/tmp/
          scp create_initial_data.py ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }}:/tmp/
          scp production.env ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }}:/tmp/

      - name: Deploy to Production Server
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }} 'bash -s' << 'DEPLOY_SCRIPT'
            set -e
            
            echo "🚀 Starting LabMyShare deployment..."
            
            # Navigate to application directory
            cd /var/www/labmyshare
            
            # Backup current setup
            if [ -f docker-compose.yml ]; then
              cp docker-compose.yml docker-compose.yml.backup.$(date +%Y%m%d_%H%M%S)
              echo "✅ Backup created"
            fi
            
            # Pull latest code
            echo "📥 Pulling latest code..."
            git fetch origin
            git reset --hard origin/main
            
            # Create directories
            echo "📁 Creating directories..."
            mkdir -p docker/nginx docker/scripts accounts/management/commands
            mkdir -p storage/{postgres,redis,static,media,logs,nginx-logs}
            mkdir -p backups/postgres
            
            # Set permissions
            chmod 755 storage/{redis,static,media,logs,nginx-logs}
            chmod 700 storage/postgres
            
            # Copy deployment files
            echo "📋 Setting up configuration files..."
            cp /tmp/docker-compose.fixed.yml docker-compose.yml
            cp /tmp/nginx.conf docker/nginx/nginx.conf
            cp /tmp/http-only.conf docker/nginx/http-only.conf
            cp /tmp/production.env .env
            
            # Setup management command
            touch accounts/management/__init__.py
            touch accounts/management/commands/__init__.py
            cp /tmp/create_initial_data.py accounts/management/commands/
            
            # Docker login
            echo "🐳 Logging into Docker registry..."
            echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin
            
            # Complete cleanup
            echo "🧹 Cleaning up existing deployment..."
            docker compose down --volumes --remove-orphans || true
            
            # Stop any running containers
            CONTAINERS=$(docker ps -q)
            if [ ! -z "$CONTAINERS" ]; then
              docker stop $CONTAINERS
            fi
            docker container prune -f
            
            # Kill processes on ports
            echo "🔓 Freeing up ports..."
            sudo fuser -k 8000/tcp 2>/dev/null || true
            sudo fuser -k 8080/tcp 2>/dev/null || true
            sudo fuser -k 5432/tcp 2>/dev/null || true
            sudo fuser -k 6379/tcp 2>/dev/null || true
            
            # Also check for any remaining Docker containers using these ports
            echo "🔍 Checking for containers using ports..."
            CONFLICTING_CONTAINERS=$(docker ps -a --filter "publish=8000" --filter "publish=8080" -q)
            if [ ! -z "$CONFLICTING_CONTAINERS" ]; then
              echo "🛑 Stopping conflicting containers..."
              docker stop $CONFLICTING_CONTAINERS || true
              docker rm $CONFLICTING_CONTAINERS || true
            fi
            
            # Wait longer for ports to be freed
            echo "⏳ Waiting for ports to be completely freed..."
            sleep 15
            
            # Verify ports are free
            echo "🔍 Verifying ports are free..."
            if netstat -tulpn | grep -q ":8000 "; then
              echo "❌ Port 8000 still in use:"
              netstat -tulpn | grep ":8000 "
              echo "🔧 Force killing processes on port 8000..."
              sudo ss -lptn 'sport = :8000' | grep -o 'pid=[0-9]*' | cut -d= -f2 | xargs -r sudo kill -9
              sleep 5
            fi
            
            if netstat -tulpn | grep -q ":8080 "; then
              echo "❌ Port 8080 still in use:"
              netstat -tulpn | grep ":8080 "
              echo "🔧 Force killing processes on port 8080..."
              sudo ss -lptn 'sport = :8080' | grep -o 'pid=[0-9]*' | cut -d= -f2 | xargs -r sudo kill -9
              sleep 5
            fi
            
            # Pull images
            echo "📥 Pulling Docker images..."
            if ! docker compose pull; then
              echo "❌ Failed to pull images"
              echo "🔍 Checking available images..."
              docker images | grep labmyshare || echo "No labmyshare images found"
              echo "🔍 Checking registry connectivity..."
              docker pull ghcr.io/${{ github.repository }}:latest || echo "Failed to pull latest image"
              exit 1
            fi
            echo "✅ Images pulled successfully"
            
            # Verify the image exists locally
            echo "🔍 Verifying Docker image..."
            if docker images | grep -q "${{ github.repository }}"; then
              echo "✅ Docker image found locally"
              docker images | grep "${{ github.repository }}"
            else
              echo "❌ Docker image not found"
              echo "Available images:"
              docker images
              exit 1
            fi
            
            # Start database and redis first
            echo "🗄️ Starting core services..."
            docker compose up -d db redis
            
            # Wait for database
            echo "⏳ Waiting for database..."
            timeout=60
            counter=0
            while [ $counter -lt $timeout ]; do
              if docker compose exec -T db pg_isready -U labmyshare -d labmyshare_db > /dev/null 2>&1; then
                echo "✅ Database ready!"
                break
              fi
              counter=$((counter + 1))
              if [ $counter -eq $timeout ]; then
                echo "❌ Database timeout"
                docker compose logs db
                exit 1
              fi
              echo "⏳ Waiting... ($counter/$timeout)"
              sleep 1
            done
            
            # Ensure database exists
            echo "🔧 Verifying database..."
            docker compose exec -T db psql -U labmyshare -lqt | grep labmyshare_db || {
              echo "📦 Creating database..."
              docker compose exec -T db createdb -U labmyshare labmyshare_db
            }
            
            # Start web container specifically
            echo "🌐 Starting web container..."
            docker compose up -d web
            
            # Wait for web container to be running
            echo "⏳ Waiting for web container to start..."
            timeout=120
            counter=0
            while [ $counter -lt $timeout ]; do
              if docker compose ps web | grep -q "Up"; then
                echo "✅ Web container is running!"
                break
              fi
              counter=$((counter + 5))
              if [ $counter -eq $timeout ]; then
                echo "❌ Web container failed to start"
                echo "=== Web Container Logs ==="
                docker compose logs web
                echo "=== Container Status ==="
                docker compose ps
                exit 1
              fi
              echo "⏳ Waiting for web container... ($counter/$timeout seconds)"
              sleep 5
            done
            
            # Wait for web service to be healthy
            echo "🏥 Waiting for web service health check..."
            timeout=180
            counter=0
            while [ $counter -lt $timeout ]; do
              if docker compose exec -T web curl -f http://localhost:8000/health/ > /dev/null 2>&1; then
                echo "✅ Web service is healthy!"
                break
              fi
              counter=$((counter + 10))
              if [ $counter -eq $timeout ]; then
                echo "❌ Web service health check failed"
                echo "=== Web Service Logs ==="
                docker compose logs web --tail=50
                echo "=== Testing manual health check ==="
                docker compose exec -T web curl -v http://localhost:8000/health/ || echo "Manual health check failed"
                exit 1
              fi
              echo "⏳ Waiting for web health... ($counter/$timeout seconds)"
              sleep 10
            done
            
            # Now start all remaining services
            echo "🚀 Starting all remaining services..."
            docker compose up -d
            
            # Verify all services are running
            echo "📊 Checking all services..."
            sleep 30
            
            EXPECTED_SERVICES="db redis web celery celery-beat nginx db-backup"
            for service in $EXPECTED_SERVICES; do
              if docker compose ps $service | grep -q "Up"; then
                echo "✅ $service is running"
              else
                echo "❌ $service is not running"
                docker compose logs $service --tail=20
                # Don't exit here, let's see which services are problematic
              fi
            done
            
            # Show final status
            echo "📋 Final container status:"
            docker compose ps
            
            # Check and configure firewall if needed
            echo "🔥 Checking firewall configuration..."
            if command -v ufw >/dev/null 2>&1; then
              echo "📋 Current UFW status:"
              sudo ufw status numbered || true
              
              # Allow port 8080 if not already allowed
              if ! sudo ufw status | grep -q "8080"; then
                echo "🔓 Opening port 8080..."
                sudo ufw allow 8080/tcp || true
              fi
              
              # Allow SSH if not already allowed
              if ! sudo ufw status | grep -q "22/tcp"; then
                echo "🔓 Ensuring SSH access..."
                sudo ufw allow 22/tcp || true
              fi
            fi
            
            # Test external port binding
            echo "🔌 Testing external port binding..."
            if netstat -tulpn | grep -q ":8080.*LISTEN"; then
              echo "✅ Port 8080 is listening"
            else
              echo "❌ Port 8080 is not listening"
              netstat -tulpn | grep -E ":(8000|8080)"
              docker compose ps
              exit 1
            fi
            
            # Run Django setup
            echo "📊 Running migrations..."
            docker compose exec -T web python manage.py migrate --noinput
            
            echo "📦 Collecting static files..."
            docker compose exec -T web python manage.py collectstatic --noinput
            
            echo "👤 Creating initial data..."
            docker compose exec -T web python manage.py create_initial_data
            
            # Final restart
            echo "🔄 Restarting services..."
            docker compose restart web nginx
            sleep 20
            
            # Show status
            echo "📊 Final status:"
            docker compose ps
            
            # Cleanup
            docker image prune -af --filter "until=24h"
            
            # Remove temp files
            rm /tmp/docker-compose.fixed.yml /tmp/nginx.conf /tmp/http-only.conf /tmp/create_initial_data.py /tmp/production.env
            
            echo "✅ Deployment completed!"
          DEPLOY_SCRIPT

      - name: Health Check
        run: |
          echo "🔍 Running comprehensive health checks..."
          
          # First, check if the server is reachable
          echo "🌐 Testing server connectivity..."
          if ! ping -c 1 ${{ secrets.SERVER_HOST }} > /dev/null 2>&1; then
            echo "❌ Server is not reachable"
            exit 1
          fi
          echo "✅ Server is reachable"
          
          # Check container status on server
          echo "📊 Checking container status on server..."
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }} 'cd /var/www/labmyshare && echo "=== Container Status ===" && docker compose ps && echo "=== Port Check ===" && netstat -tulpn | grep -E ":(8000|8080|5432|6379)" && echo "=== Nginx Status ===" && docker compose logs nginx --tail=10 && echo "=== Web Status ===" && docker compose logs web --tail=20'
          
          # Test direct port 8080 connectivity
          echo "🔌 Testing port 8080 connectivity..."
          if nc -z ${{ secrets.SERVER_HOST }} 8080; then
            echo "✅ Port 8080 is open"
          else
            echo "❌ Port 8080 is not accessible"
            echo "🔍 Checking firewall and nginx configuration..."
            ssh ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }} 'cd /var/www/labmyshare && echo "=== UFW Status ===" && sudo ufw status && echo "=== Nginx Config Test ===" && docker compose exec nginx nginx -t && echo "=== All Container Logs ===" && docker compose logs --tail=50'
            exit 1
          fi
          
          # Try health check with more details
          echo "🏥 Attempting health check..."
          for i in {1..5}; do
            echo "🔍 Health check attempt $i/5..."
            
            # Try different endpoints
            for endpoint in "/health/" "/health" "/"; do
              echo "Testing endpoint: $endpoint"
              if curl -v -f -m 15 "http://backend.beautyspabyshea.co.uk:8080$endpoint" 2>&1; then
                echo "✅ Health check passed on $endpoint!"
                exit 0
              fi
            done
            
            if [ $i -lt 5 ]; then
              echo "⏳ Health check failed, waiting 20 seconds before retry..."
              sleep 20
            fi
          done
          
          echo "❌ All health check attempts failed"
          echo "🔍 Final diagnostics..."
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }} 'cd /var/www/labmyshare && echo "=== Final Container Status ===" && docker compose ps && echo "=== Web Container Logs ===" && docker compose logs web --tail=50 && echo "=== Nginx Container Logs ===" && docker compose logs nginx --tail=30'
          exit 1

      - name: Deployment Summary
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ Deployment successful!"
            echo "🌐 Application: http://backend.beautyspabyshea.co.uk:8080"
            echo "🔍 Health: http://backend.beautyspabyshea.co.uk:8080/health/"
            echo "📚 API docs: http://backend.beautyspabyshea.co.uk:8080/swagger/"
          else
            echo "❌ Deployment failed"
          fi

  cleanup:
    needs: deploy
    runs-on: ubuntu-latest
    if: always() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')

    steps:
      - name: Clean up old container images
        run: |
          gh api --method GET \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "/user/packages/container/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')/versions" \
            --field per_page=100 | \
          jq -r '.[5:] | .[].id' | \
          head -20 | \
          xargs -I {} gh api --method DELETE \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "/user/packages/container/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')/versions/{}" || echo "Cleanup completed"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
