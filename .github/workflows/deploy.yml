name: Deploy to Production

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: labmyshare2020
          POSTGRES_DB: labmyshare_db
          POSTGRES_USER: labmyshare
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-django pytest-cov

      - name: Set up test environment
        run: |
          cp .env.example .env
          echo "DEBUG=True" >> .env
          echo "SECRET_KEY=test-secret-key-for-github-actions" >> .env
          echo "DB_NAME=labmyshare_db" >> .env
          echo "DB_USER=labmyshare" >> .env
          echo "DB_PASSWORD=labmyshare2020" >> .env
          echo "DB_HOST=localhost" >> .env
          echo "DB_PORT=5432" >> .env
          echo "REDIS_URL=redis://localhost:6379/1" >> .env
          echo "CELERY_BROKER_URL=redis://localhost:6379/0" >> .env
          echo "CELERY_RESULT_BACKEND=redis://localhost:6379/0" >> .env

      - name: Run migrations
        run: |
          python manage.py migrate --run-syncdb

      - name: Run tests
        run: |
          python manage.py test

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    permissions:
      contents: read
      packages: write

    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

  deploy:
    needs: [test, build]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    environment:
      name: production
      url: http://backend.beautyspabyshea.co.uk:8080

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.7.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts

      - name: Deploy to Production Server
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SERVER_HOST }} 'bash -s' << 'DEPLOY_SCRIPT'
            set -e
            
            echo "🚀 Starting deployment with full cleanup..."
            
            cd /var/www/labmyshare
            
            # COMPLETE CLEANUP - Clear everything
            echo "🧹 Complete system cleanup..."
            
            # Stop and remove all containers
            docker compose down --volumes --remove-orphans 2>/dev/null || true
            docker stop $(docker ps -aq) 2>/dev/null || true
            docker rm $(docker ps -aq) 2>/dev/null || true
            
            # Remove ALL Docker artifacts except persistent data
            docker system prune -af --volumes
            docker builder prune -af
            docker image rm $(docker images -q) 2>/dev/null || true
            
            # Kill processes on ports
            sudo fuser -k 8000/tcp 2>/dev/null || true
            sudo fuser -k 8080/tcp 2>/dev/null || true
            sudo fuser -k 5432/tcp 2>/dev/null || true
            sudo fuser -k 6379/tcp 2>/dev/null || true
            
            sleep 15  # Wait for cleanup to complete
            
            # Update code
            echo "📥 Updating code..."
            git fetch origin
            git reset --hard origin/main
            
            # Create persistent storage directories (preserve database data)
            echo "📁 Setting up persistent storage..."
            mkdir -p docker/nginx accounts/management/commands
            mkdir -p storage/{postgres,redis,static,media,logs,nginx-logs}
            mkdir -p backups/postgres
            
            # Set permissions
            sudo chown -R $USER:$USER storage/
            chmod 755 storage/{redis,static,media,logs,nginx-logs}
            chmod 700 storage/postgres
            
            # Create Docker Compose configuration
            echo "📋 Creating Docker Compose configuration..."
            cat > docker-compose.yml << 'EOF'
          services:
            db:
              container_name: labmyshare_db
              image: postgres:15
              restart: unless-stopped
              environment:
                POSTGRES_DB: labmyshare_db
                POSTGRES_USER: labmyshare
                POSTGRES_PASSWORD: labmyshare2020
              volumes:
                - postgres_data:/var/lib/postgresql/data/
                - ./backups/postgres:/backups
              ports:
                - "127.0.0.1:5432:5432"
              healthcheck:
                test: ["CMD-SHELL", "pg_isready -U labmyshare -d labmyshare_db"]
                interval: 10s
                timeout: 5s
                retries: 5
                start_period: 30s
              networks:
                - labmyshare_network
          
            redis:
              container_name: labmyshare_redis
              image: redis:7-alpine
              restart: unless-stopped
              command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
              volumes:
                - redis_data:/data
              ports:
                - "127.0.0.1:6379:6379"
              healthcheck:
                test: ["CMD", "redis-cli", "ping"]
                interval: 10s
                timeout: 5s
                retries: 5
              networks:
                - labmyshare_network
          
            web:
              container_name: labmyshare_web
              image: ghcr.io/${{ github.repository }}:latest
              restart: unless-stopped
              command: >
                sh -c "
                  echo 'Waiting for database...' &&
                  until nc -z db 5432; do sleep 2; done &&
                  echo 'Database ready!' &&
                  python manage.py migrate --noinput &&
                  python manage.py collectstatic --noinput &&
                  gunicorn labmyshare.wsgi:application --bind 0.0.0.0:8000 --workers 4 --threads 2 --timeout 120
                "
              volumes:
                - static_volume:/app/staticfiles
                - media_volume:/app/media
                - logs_volume:/app/logs
              ports:
                - "127.0.0.1:8000:8000"
              env_file:
                - .env
              depends_on:
                db:
                  condition: service_healthy
                redis:
                  condition: service_healthy
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 90s
              networks:
                - labmyshare_network
          
            celery:
              container_name: labmyshare_celery
              image: ghcr.io/${{ github.repository }}:latest
              restart: unless-stopped
              command: >
                sh -c "
                  until nc -z db 5432 && nc -z redis 6379; do sleep 2; done &&
                  celery -A labmyshare worker --loglevel=info --concurrency=4
                "
              volumes:
                - media_volume:/app/media
                - logs_volume:/app/logs
              env_file:
                - .env
              depends_on:
                - db
                - redis
              healthcheck:
                test: ["CMD", "celery", "-A", "labmyshare", "inspect", "ping"]
                interval: 30s
                timeout: 10s
                retries: 3
              networks:
                - labmyshare_network
          
            celery-beat:
              container_name: labmyshare_celery_beat
              image: ghcr.io/${{ github.repository }}:latest
              restart: unless-stopped
              command: >
                sh -c "
                  until nc -z db 5432 && nc -z redis 6379; do sleep 2; done &&
                  celery -A labmyshare beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
                "
              volumes:
                - logs_volume:/app/logs
              env_file:
                - .env
              depends_on:
                - db
                - redis
              networks:
                - labmyshare_network
          
            nginx:
              container_name: labmyshare_nginx
              image: nginx:alpine
              restart: unless-stopped
              ports:
                - "8080:80"
              volumes:
                - ./docker/nginx/http-only.conf:/etc/nginx/conf.d/default.conf:ro
                - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
                - static_volume:/var/www/static:ro
                - media_volume:/var/www/media:ro
                - nginx_logs:/var/log/nginx
              depends_on:
                web:
                  condition: service_healthy
              networks:
                - labmyshare_network
          
          volumes:
            postgres_data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/postgres
            redis_data:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/redis
            static_volume:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/static
            media_volume:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/media
            logs_volume:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/logs
            nginx_logs:
              driver: local
              driver_opts:
                type: none
                o: bind
                device: /var/www/labmyshare/storage/nginx-logs
          
          networks:
            labmyshare_network:
              driver: bridge
          EOF
            
            # Create Nginx configuration
            echo "🌐 Creating Nginx configuration..."
            mkdir -p docker/nginx
            
            cat > docker/nginx/nginx.conf << 'NGINX_CONF'
          user nginx;
          worker_processes auto;
          error_log /var/log/nginx/error.log warn;
          pid /var/run/nginx.pid;
          
          events {
            worker_connections 1024;
          }
          
          http {
            include /etc/nginx/mime.types;
            default_type application/octet-stream;
            sendfile on;
            keepalive_timeout 65;
            client_max_body_size 10M;
            
            gzip on;
            gzip_vary on;
            gzip_min_length 1024;
            gzip_types text/plain text/css application/json application/javascript text/xml application/xml;
            
            include /etc/nginx/conf.d/*.conf;
          }
          NGINX_CONF
            
            cat > docker/nginx/http-only.conf << 'NGINX_SITE'
          upstream labmyshare {
            server web:8000 max_fails=3 fail_timeout=30s;
          }
          
          server {
            listen 80;
            server_name backend.beautyspabyshea.co.uk localhost;
            
            # Security headers
            add_header X-Frame-Options "SAMEORIGIN" always;
            add_header X-Content-Type-Options "nosniff" always;
            add_header X-XSS-Protection "1; mode=block" always;
            
            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            location / {
              proxy_pass http://labmyshare;
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $scheme;
            }
            
            location /health/ {
              proxy_pass http://labmyshare;
              proxy_set_header Host $host;
              access_log off;
            }
            
            location /health {
              proxy_pass http://labmyshare;
              proxy_set_header Host $host;
              access_log off;
            }
            
            location /static/ {
              alias /var/www/static/;
              expires 30d;
            }
            
            location /media/ {
              alias /var/www/media/;
              expires 7d;
            }
          }
          NGINX_SITE
            
            # Create environment file
            echo "⚙️ Creating environment configuration..."
            cat > .env << 'ENV_FILE'
          SECRET_KEY=ghfjgk.hl;iogulfkydjtxfgcvjbk.hllfkdtjxgchvjgkifuydcghvjgv
          DEBUG=False
          ALLOWED_HOSTS=backend.beautyspabyshea.co.uk,localhost,127.0.0.1
          
          DB_NAME=labmyshare_db
          DB_USER=labmyshare
          DB_PASSWORD=labmyshare2020
          DB_HOST=db
          DB_PORT=5432
          
          REDIS_URL=redis://redis:6379/1
          CELERY_BROKER_URL=redis://redis:6379/0
          CELERY_RESULT_BACKEND=redis://redis:6379/0
          
          EMAIL_HOST=smtp.resend.com
          EMAIL_PORT=587
          EMAIL_HOST_USER=resend
          EMAIL_HOST_PASSWORD=re_ZBwZZ2tj_AMtGvcpxoa1DofEXdV3BKM2f
          DEFAULT_FROM_EMAIL=noreply@beautyspabyshea.co.uk
          ENV_FILE
            
            # Create management command
            echo "👤 Creating admin setup..."
            mkdir -p accounts/management/commands
            touch accounts/management/__init__.py
            touch accounts/management/commands/__init__.py
            
            cat > accounts/management/commands/create_initial_data.py << 'MGMT_CMD'
          from django.core.management.base import BaseCommand
          from django.contrib.auth import get_user_model
          
          User = get_user_model()
          
          class Command(BaseCommand):
              help = "Create initial data"
              
              def handle(self, *args, **options):
                  try:
                      admin_email = "admin@labmyshare.com"
                      if not User.objects.filter(email=admin_email).exists():
                          User.objects.create_superuser(
                              username="admin",
                              email=admin_email,
                              password="admin123"
                          )
                          self.stdout.write(self.style.SUCCESS("✅ Superuser created"))
                      else:
                          self.stdout.write(self.style.WARNING("ℹ️ Superuser already exists"))
                  except Exception as e:
                      self.stdout.write(self.style.ERROR(f"❌ Error: {e}"))
          MGMT_CMD
            
            # Docker login and pull
            echo "🐳 Docker operations..."
            echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin
            
            if ! docker compose pull; then
              echo "❌ Failed to pull images"
              exit 1
            fi
            
            # Deploy services
            echo "🚀 Starting deployment..."
            
            # Start core services first
            docker compose up -d db redis
            
            # Wait for database
            echo "⏳ Waiting for database..."
            timeout=60
            counter=0
            while [ $counter -lt $timeout ]; do
              if docker compose exec -T db pg_isready -U labmyshare -d labmyshare_db > /dev/null 2>&1; then
                echo "✅ Database ready!"
                break
              fi
              counter=$((counter + 1))
              if [ $counter -eq $timeout ]; then
                echo "❌ Database timeout"
                docker compose logs db
                exit 1
              fi
              sleep 1
            done
            
            # Start web service
            docker compose up -d web
            
            # Wait for web health
            echo "⏳ Waiting for web service..."
            timeout=120
            counter=0
            while [ $counter -lt $timeout ]; do
              if docker compose exec -T web curl -f http://localhost:8000/health/ > /dev/null 2>&1; then
                echo "✅ Web service ready!"
                break
              fi
              counter=$((counter + 10))
              if [ $counter -eq $timeout ]; then
                echo "❌ Web service timeout"
                docker compose logs web --tail=50
                exit 1
              fi
              sleep 10
            done
            
            # Start remaining services
            docker compose up -d
            sleep 30
            
            # Run Django setup
            echo "⚙️ Django setup..."
            docker compose exec -T web python manage.py migrate --noinput
            docker compose exec -T web python manage.py collectstatic --noinput
            docker compose exec -T web python manage.py create_initial_data
            
            # Configure firewall
            echo "🔥 Configuring firewall..."
            if command -v ufw >/dev/null 2>&1; then
              sudo ufw allow 8080/tcp || true
              sudo ufw allow 22/tcp || true
            fi
            
            # Final restart
            docker compose restart web nginx
            sleep 20
            
            # Show status
            echo "📊 Final status:"
            docker compose ps
            
            # Test database persistence
            DB_SIZE=$(docker compose exec -T db psql -U labmyshare -d labmyshare_db -t -c "SELECT pg_size_pretty(pg_database_size('labmyshare_db'));" | tr -d ' ')
            echo "✅ Database size: $DB_SIZE"
            
            echo "✅ Deployment completed!"
            echo "🌐 HTTP: http://backend.beautyspabyshea.co.uk:8080"
            echo "🗄️ Database persistent at: /var/www/labmyshare/storage/postgres"
          DEPLOY_SCRIPT

      - name: Health Check
        run: |
          echo "🔍 Health check..."
          
          # Test connectivity
          if nc -z ${{ secrets.SERVER_HOST }} 8080; then
            echo "✅ Port 8080 accessible"
          else
            echo "❌ Port 8080 not accessible"
            exit 1
          fi
          
          # Test endpoints
          for i in {1..5}; do
            echo "Health check attempt $i/5..."
            if curl -f -m 15 "http://backend.beautyspabyshea.co.uk:8080/health/" 2>&1; then
              echo "✅ Health check passed!"
              exit 0
            fi
            sleep 20
          done
          
          echo "❌ Health checks failed"
          exit 1

      - name: Deployment Summary
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ Deployment successful!"
            echo "🌐 Application: http://backend.beautyspabyshea.co.uk:8080"
            echo "🔍 Health: http://backend.beautyspabyshea.co.uk:8080/health/"
            echo "📚 API docs: http://backend.beautyspabyshea.co.uk:8080/swagger/"
            echo "👨‍💼 Admin: http://backend.beautyspabyshea.co.uk:8080/admin/"
            echo "🗄️ Database: Persistent PostgreSQL"
          else
            echo "❌ Deployment failed"
          fi
